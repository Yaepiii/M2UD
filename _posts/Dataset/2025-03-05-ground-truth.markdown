---
title: "Ground Truth"
layout: post
date: 2025-03-05 12:00
image: /assets/image/sia.png
headerImage: false
tag:
- markdown
- components
- extra
hidden: false
category: Dataset
author: Yanpeng Jia
description: Ground Truth
---

# Ground Truth

## Localization Ground Truth

![figure](../../assets/image/figure7.png)

For outdoor sequences, the original absolute poses of the robots are obtained from RTK. However, due to the notorious multipath and non-line-of-sight (NLOS) phenomenon, the original data contain numerous outliers and significant errors, as shown in Figures 7 (A), (C). Therefore, the ground truth smooth kit is utilized to smooth the original data and generate high-quality localization ground truths, as shown in Figures 7 (B) and (D). For indoor sequences, our developed multi-sensor fusion [SLAM algorithm](https://yaepiii.github.io/GR-LOAM_Plus_Plus/) is executed offline to generate accurate smooth trajectories ground truth. Several sequences that returned to the start point are selected to verify the reliability of this ground truth generation method by analyzing the end-to-end errors. The results indicate that an end-to-end error of 0.031 m is observed after traversing 130 m in the long corridor test sequence, while an end-to-end error of 0.1 m is recorded after covering 601 m in the parking sequence. Therefore, we claim that this method is considered reliable. Figure 9 visually presents the ground truth generated by this method, along with the distances between the starting and ending points. For indoor-outdoor mixed sequences, our developed multi-sensor fusion SLAM is also executed offline, and when RTK data is available, RTK factor constraints are incorporated into the factor graph to enhance the reliability of the ground truth.

![figure](../../assets/image/figure9.png)

## Mapping Ground Truth

To advance research and development in mapping algorithms, a FARO Focus Premium 70M [3D laser scanner](https://www.weiyang3d.com/en/h-col-124.html) is utilized to capture a 3D scene map of a park and a dormitory building, as illustrated in Figure 8. This 3D laser scanner has a maximum visual range of 614 m and is capable of capturing 500,000 points per second, achieving a ranging error of $\pm$ 1 mm and a 3D positioning accuracy of 3.5 mm at a distance of 25 m. We match the scans offline and manually remove dynamic ghosting to construct an accurate global map ground truths. Additionally, several handheld and wheeled robot sequences additionally provided for these scenarios, named as "[mapping](https://1drv.ms/f/c/c1806c2e19f2193f/En98Iep0qBdMlo8iv0jsiFABJzSGdj5hNy8faTAonoD9jw?e=KtuRLW)" in the open-source dataset, are specifically intended for map building and evaluation, whose routes are designed based on the scanning trajectories used during ground truth construction.
